在计算机数据存储领域，一直是RDBMS的天下，在传统企业的应用领域，许多应用系统设计都是面向数据库设计，也就是**先设计数据库然后设计程序**，从而导致
**关系模型绑架对象模型**。  
关系数据库有着难以克服的缺陷——糟糕的海量数据处理能力及僵硬的设计约束。所以，为了解决这些问题，NoSQL概念被提出。  
**NoSQL，主要指非关系的、分布式的、支持海量数据存储的数据库设计模式**。其中，HBase是这类NoSQL的杰出代表。  
HBase之所以能够处理海量数据，其根本在于和传统RDBMS设计具有不同思路。RDBMS对存储其上的数据有很多约束，学习时都要学习数据库设计范式，事实上，是在数据
存储中包含了一部分业务逻辑。而NoSQL则简单的认为，数据库就是存储数据的，业务逻辑应该由应用程序去处理。  

### 一.Hbase可伸缩架构
HBase为可伸缩海量数据存储设计，实现面向在线业务的实时数据访问延迟。**HBase的伸缩性主要依赖其可分裂的HRegion以及可伸缩的分布式文件系统HDFS实现**。  

下图为HBase的架构：  
![Hbase架构](https://static001.geekbang.org/resource/image/9f/f7/9f4220274ef0a6bcf253e8d012a6d4f7.png)  
**HRegion是负责存储数据的主要进程，应用程序对数据的读写都是通过与HRegion通信完成**。应用程序如果想要访问一个数据，必须先找到HRegion，将数据读写操作
提交给HRegion，由HRegion完成存储层面的数据操作。  
**HRegionServer是物理服务器，每个HRegionServer上可以启动多个HRegion实例**。当一个HRegion过大时，达到了设置的阈值，会分裂成两个HRegion，HRegion会
在整个集群里进行迁移，使得HRegionServer负载均衡。  
**每个HRegion中存储的是一段key值区间[key1, key2)的数据，所有HRegion的信息，如存储的key值区间、所在HRegionServer地址、访问端口等，都记录在HMaster上。
**为了保证HMaster的高可用，HBase会启动多个HMaster，并通过Zookeeper选举一个主服务器。  

HBase的调用时序图如下：  
![HBase调用时序图](https://static001.geekbang.org/resource/image/9f/ab/9fd982205b06ecd43053202da2ae08ab.png)  
应用程序先请求zookeeper，获取主HMaster地址，然后将key值输入，获取这个key所在的HRegionServer地址，最后请求HRegionServer上对应的HRegion，获取所需数据。  
数据的写入过程也类似，需要先获得HRegion才能继续操作。**HRegion会把数据存储在若干个HFile格式的文件中，HFile文件使用HDFS进行存储，在整个集群中分布且
高可用**。当一个HRegion中的数据量太多时，HRegion连同其存储的HFile会分裂成两个HRegion，并根据集群当前的负载进行迁移。如果集群中新加入了服务器，因为
其负载较低，这时也会发生HRegion的迁移。  

### 二.Hbase可扩展数据模型
HBase是基于列族来设计其数据存储结构的，这是一种可扩展的设计，如下图所示：  
![Hbase列族](https://static001.geekbang.org/resource/image/74/6f/74b3aac940abae8a571cc94f2226656f.png)  
HBase在创建表的时候，只需要指定列族的名字，无需指定字段（column）。字段是在数据写入时进行指定。通过这种方式，数据表不需要预设字段，可以随意扩展应用程序的数据结构。  
**HBase这种列族设计，实际上是把字段的名称和字段的值，以key-value的方式一起存储在HBase中。实际写入时，可以随意指定字段名称，即使有几百万个字段也能轻松应对。**  

列族的缺陷：  
（1）不好查询，只能根据rowkey查询，范围查询scan性能较低；  
（2）查询无法做到索引优化，因为列不固定；  
（3）做不了事务控制；  

### 三.Hbase的高性能存储
传统的机械磁盘的访问特性是**连续读写很快，随机读写很慢**。这是因为机械磁盘靠磁头访问磁盘上的数据，磁盘要落到数据所在的磁道上，这个过程需要较长的寻址时间。如果数据不连续存储，磁头需要不停移动，浪费大量时间。  
为了提高数据的写入速度，HBase使用了**LSM树**的数据结构进行存储。其全名是Log Structured Merge Tree。数据写入时以Log方式连续写入，然后异步对磁盘上的多个LSM树进行合并。如下图所示：  
![LSM树](https://static001.geekbang.org/resource/image/5f/3b/5fbd17a9c0b9f1a10347a4473d00ad3b.jpg)  

LSM树可以看作一个N阶合并树。数据写操作（包括插入、修改、删除）都在内存中进行，且都会创建一个新记录（修改会记录新的数据值，删除会打一个删除标记）。**这些数据在内存中仍然是一棵排序树，当数据量超过设定的阈值时，内存会刷写到磁盘上，该排序树会和磁盘上最新的排序树合并**。当这棵排序树的数据量也超过设定阈值后，会和磁盘上下一级的排序树合并。合并过程中，会用最新更新的数据覆盖旧的数据（或记录为不同版本）。  
**在进行读写操作时，总是从内存中的排序树开始搜索，如果没有找到，则从磁盘上的排序树顺序查找。**  
在LSM树上进行一次数据更新不需要磁盘访问，在内存中即可完成。当数据访问以写为主，读操作集中在最近写入的数据上时，使用LSM树可以极大程度减少磁盘访问的次数，加快访问速度。  












